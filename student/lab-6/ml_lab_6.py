# -*- coding: utf-8 -*-
"""ml_lab_6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gK6W4Q6okpqRcmLJW6PUOaugPck2nU40

# **Задание:**

1. Выберите набор данных (датасет) для решения задачи классификации или регресии.
2. В случае необходимости проведите удаление или заполнение пропусков и кодирование категориальных признаков.
3. С использованием метода train_test_split разделите выборку на обучающую и тестовую.
4. Обучите две ансамблевые модели. Оцените качество моделей с помощью одной из подходящих для задачи метрик. Сравните качество полученных моделей.
5. Произведите для каждой модели подбор значений одного гиперпараметра. В зависимости от используемой библиотеки можно применять функцию GridSearchCV, использовать перебор параметров в цикле, или использовать другие методы.
6.Повторите пункт 4 для найденных оптимальных значений гиперпараметров. Сравните качество полученных моделей с качеством моделей, полученных в пункте 4..

Датасет: [wine](https://www.kaggle.com/brynja/wineuci/downloads/wineuci.zip/1)
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import learning_curve, validation_curve
from sklearn.model_selection import KFold, RepeatedKFold, LeaveOneOut, LeavePOut, ShuffleSplit, StratifiedKFold
from sklearn.model_selection import cross_val_score, cross_validate
from sklearn.metrics import roc_curve,confusion_matrix, roc_auc_score, accuracy_score, balanced_accuracy_score

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LinearRegression

import warnings
from google.colab import files
import os
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier

from sklearn.metrics import accuracy_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score


import warnings
from sklearn.model_selection import GridSearchCV

warnings.filterwarnings('ignore')
plt.style.use('ggplot')

# Считывание данных
data = pd.read_csv('Wine.csv', sep=";")
data.head()

# Типы данных
data.dtypes

# Проверка на пустые значения
for col in data.columns:
    print('{} - {}'.format(col, data[data[col].isnull()].shape[0]))

# Размерность данных
data.shape

CLASS = 'Class'
RANDOM_STATE = 17
TEST_SIZE = 0.3

X = data.drop(CLASS, axis=1).values
Y = data[CLASS].values

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=Y)
print('X_train: {}'.format(X_train.shape))
print('X_test: {}'.format(X_test.shape))

"""### **Обучение**

Случайный лес
"""

# n_estimators = 10 (default)
rfc = RandomForestClassifier().fit(X_train, Y_train)
predicted_rfc = rfc.predict(X_test)

accuracy_score(Y_test, predicted_rfc)

"""AdaBoost"""

abc = AdaBoostClassifier().fit(X_train, Y_train)
predicted_abc = abc.predict(X_test)

accuracy_score(Y_test, predicted_abc)

"""### **Подбор гиперпараметров**

Случайный лес
"""

rfc_n_range = np.array(range(5,100,5))
rfc_tuned_parameters = [{'n_estimators': rfc_n_range}]
rfc_tuned_parameters

warnings.filterwarnings('ignore')
gs_rfc = GridSearchCV(RandomForestClassifier(), rfc_tuned_parameters, cv=5, scoring='accuracy')
gs_rfc.fit(X_train, Y_train)

gs_rfc.best_params_

plt.plot(rfc_n_range, gs_rfc.cv_results_['mean_test_score'])

"""AdaBoost"""

abc_n_range = np.array(range(5,100,5))
abc_tuned_parameters = [{'n_estimators': abc_n_range}]
abc_tuned_parameters

gs_abc = GridSearchCV(AdaBoostClassifier(), abc_tuned_parameters, cv=5, scoring='accuracy')
gs_abc.fit(X_train, Y_train)

gs_abc.best_params_

plt.plot(abc_n_range, gs_abc.cv_results_['mean_test_score'])

"""### **Сравнение моделей после подбора гиперпараметров**

Случайный лес
"""

rfc_optimized = RandomForestClassifier(n_estimators=gs_rfc.best_params_['n_estimators']).fit(X_train, Y_train)
predicted_rfc_opt = rfc_optimized.predict(X_test)

accuracy_score(Y_test, predicted_rfc_opt)

"""AdaBoost"""

abc_optimized = RandomForestClassifier(n_estimators=gs_abc.best_params_['n_estimators']).fit(X_train, Y_train)
predicted_abc_opt = abc_optimized.predict(X_test)

accuracy_score(Y_test, predicted_abc_opt)